{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "from cleaning import *\n",
    "from metrics import *\n",
    "from implementations import *\n",
    "from definitions import ROOT_DIR\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(ROOT_DIR, 'dataset_to_release')\n",
    "x_tr, x_te, y_tr, tr_ids, te_ids = load_csv_data(dataset_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished running PCA: keeping 15 components to explain >99% variance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_train = clean_continuous(x_tr, 0.8, False, 99, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_x_tr, clean_x_te, y_tr_set, y_te_set = split_data(clean_train, y_tr, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'gradient descent' : [0.01, 0.7], \n",
    "               'stochastic gradient descent': [0.01, 0.7],\n",
    "               'least squares': [0.01, 0.7],\n",
    "               'ridge regression': [0.01, 0.7],\n",
    "               'logistic regression': [0.01, 0.7],\n",
    "               'reg logistic regression': [0.01, 0.7]}#complete w our results as ['model', lambda_, gamma]\n",
    "\n",
    "models = ['gradient descent', 'stochastic gradient descent', 'least squares', 'ridge regression',  'logistic regression', 'reg logistic regression']\n",
    "mapping_threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on gradient descent\n",
      "\n",
      "---------- GRADIENT DESCENT ----------\n",
      "train rmse = 6.8373768375749256e+84 - test rmse = 6.511396406278432e+84\n",
      "=========== TRAIN metrics ===========\n",
      "Accuracy: 0.5527619047619048 - F1 score 0.1003831417624521\n",
      "Specificity: 0.5752543076603696 - Sensitivity: 0.302540415704388\n",
      "Precision: 0.060174552135966924\n",
      "=========== TEST metrics ===========\n",
      "Accuracy: 0.5628332063975628 - F1 score 0.13813813813813813\n",
      "Specificity: 0.5848101265822785 - Sensitivity: 0.359375\n",
      "Precision: 0.08550185873605948\n",
      "\n",
      "working on stochastic gradient descent\n",
      "\n",
      "---------- STOCHASTIC GRADIENT DESCENT ----------\n",
      "train rmse = 4.366162243260519e+151 - test rmse = 4.331190991892111e+151\n",
      "=========== TRAIN metrics ===========\n",
      "Accuracy: 0.5045714285714286 - F1 score 0.11920081273281408\n",
      "Specificity: 0.5133900768112933 - Sensitivity: 0.4064665127020785\n",
      "Precision: 0.06984126984126984\n",
      "=========== TEST metrics ===========\n",
      "Accuracy: 0.5163747143945163 - F1 score 0.14535666218034993\n",
      "Specificity: 0.5265822784810127 - Sensitivity: 0.421875\n",
      "Precision: 0.08780487804878048\n",
      "\n",
      "working on least squares\n",
      "\n",
      "---------- LEAST SQUARES ----------\n",
      "train rmse = 0.9978742808917015 - test rmse = 0.9998604660272319\n",
      "=========== TRAIN metrics ===========\n",
      "Accuracy: 0.5169523809523809 - F1 score 0.18665811417575368\n",
      "Specificity: 0.5030101723064148 - Sensitivity: 0.6720554272517321\n",
      "Precision: 0.10837988826815642\n",
      "=========== TEST metrics ===========\n",
      "Accuracy: 0.5034272658035034 - F1 score 0.1829573934837093\n",
      "Specificity: 0.4962025316455696 - Sensitivity: 0.5703125\n",
      "Precision: 0.10895522388059702\n",
      "\n",
      "working on ridge regression\n",
      "\n",
      "---------- RIDGE REGRESSION ----------\n",
      "train rmse = 0.997874588554937 - test rmse = 0.9998454537946441\n",
      "=========== TRAIN metrics ===========\n",
      "Accuracy: 0.5165714285714286 - F1 score 0.18653846153846154\n",
      "Specificity: 0.5025949761262196 - Sensitivity: 0.6720554272517321\n",
      "Precision: 0.10829921845924823\n",
      "=========== TEST metrics ===========\n",
      "Accuracy: 0.5072353389185073 - F1 score 0.18411097099621693\n",
      "Specificity: 0.5004219409282701 - Sensitivity: 0.5703125\n",
      "Precision: 0.10977443609022557\n",
      "\n",
      "working on logistic regression\n",
      "\n",
      "---------- LOGISTIC REGRESSION ----------\n",
      "train rmse = 1.0213834731583125 - test rmse = 1.0333107783623068\n",
      "=========== TRAIN metrics ===========\n",
      "Accuracy: 0.5127619047619048 - F1 score 0.1827476038338658\n",
      "Specificity: 0.4994810047747561 - Sensitivity: 0.6605080831408776\n",
      "Precision: 0.10604375231738969\n",
      "=========== TEST metrics ===========\n",
      "Accuracy: 0.49352627570449353 - F1 score 0.18404907975460125\n",
      "Specificity: 0.4835443037974684 - Sensitivity: 0.5859375\n",
      "Precision: 0.1091703056768559\n",
      "\n",
      "working on reg logistic regression\n",
      "\n",
      "---------- REG LOGISTIC REGRESSION ----------\n",
      "train rmse = 1.0220485923778955 - test rmse = 1.0343759143895106\n",
      "=========== TRAIN metrics ===========\n",
      "Accuracy: 0.5158095238095238 - F1 score 0.18158403090792016\n",
      "Specificity: 0.5036329665767075 - Sensitivity: 0.651270207852194\n",
      "Precision: 0.10549943883277217\n",
      "=========== TEST metrics ===========\n",
      "Accuracy: 0.4859101294744859 - F1 score 0.17582417582417584\n",
      "Specificity: 0.47763713080168774 - Sensitivity: 0.5625\n",
      "Precision: 0.10419681620839363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initial_w = np.zeros(clean_x_tr.shape[1])\n",
    "\n",
    "for model in models:\n",
    "    lambda_ = best_params[model][0]\n",
    "    gamma = best_params[model][1]\n",
    "    print(f'working on {model}')\n",
    "    w, loss = train(model,y_tr_set, clean_x_tr, initial_w, 500, gamma, lambda_)\n",
    "    train_predictions = np.where(np.dot(clean_x_tr,w) < mapping_threshold, -1, 1)\n",
    "    test_predictions = np.where(np.dot(clean_x_te, w) < mapping_threshold, -1, 1)\n",
    "    tr_err = y_tr_set - np.dot(clean_x_tr, w)\n",
    "    te_err = y_te_set - np.dot(clean_x_te, w)\n",
    "    train_rmse = np.sqrt(2*hp.compute_mse(tr_err))\n",
    "    test_rmse = np.sqrt(2*hp.compute_mse(te_err))\n",
    "    print('')\n",
    "    print(f'---------- {model.upper()} ----------')\n",
    "    print(f'train rmse = {train_rmse} - test rmse = {test_rmse}')\n",
    "    train_metrics = calculate_metrics(y_tr_set, train_predictions)\n",
    "    test_metrics = calculate_metrics(y_te_set, test_predictions)\n",
    "    print('=========== TRAIN metrics ===========')\n",
    "    prettyprint(train_metrics)\n",
    "    print('=========== TEST metrics ===========')\n",
    "    prettyprint(test_metrics)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
