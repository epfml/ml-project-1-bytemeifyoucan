{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "arr_2d = np.array([888,1,2,3,0,0,888,888,0,5,0,0,0])\n",
    "nb = np.count_nonzero(arr_2d==0)\n",
    "print(nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[6 7]]\n",
      "[6 7]\n"
     ]
    }
   ],
   "source": [
    "arr2 = np.array([0,1,2,3,0,0,888,888,0,5,0,0,0])\n",
    "idxpred = np.array(np.where(arr_2d == 888))\n",
    "idxgt= np.array(np.where(arr2 == 888))\n",
    "common = np.intersect1d(idxpred, idxgt)\n",
    "tp = len(common)\n",
    "print(tp)\n",
    "print(idxgt)\n",
    "print(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(data_path, sub_sample=False):\n",
    "    \"\"\"\n",
    "    This function loads the data and returns the respectinve numpy arrays.\n",
    "    Remember to put the 3 files in the same folder and to not change the names of the files.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): datafolder path\n",
    "        sub_sample (bool, optional): If True the data will be subsempled. Default to False.\n",
    "\n",
    "    Returns:\n",
    "        x_train (np.array): training data\n",
    "        x_test (np.array): test data\n",
    "        y_train (np.array): labels for training data in format (-1,1)\n",
    "        train_ids (np.array): ids of training data\n",
    "        test_ids (np.array): ids of test data\n",
    "    \"\"\"\n",
    "    y_train = np.genfromtxt(\n",
    "        os.path.join(data_path, \"y_train.csv\"),\n",
    "        delimiter=\",\",\n",
    "        skip_header=1,\n",
    "        dtype=int,\n",
    "        usecols=1,\n",
    "    )\n",
    "    print('ytrain done')\n",
    "    x_train = np.genfromtxt(\n",
    "        os.path.join(data_path, \"x_train.csv\"), delimiter=\",\", skip_header=1\n",
    "    )\n",
    "    print('xtrain done')\n",
    "    x_test = np.genfromtxt(\n",
    "        os.path.join(data_path, \"x_test.csv\"), delimiter=\",\", skip_header=1\n",
    "    )\n",
    "    print('xtest done')\n",
    "\n",
    "    train_ids = x_train[:, 0].astype(dtype=int)\n",
    "    test_ids = x_test[:, 0].astype(dtype=int)\n",
    "    x_train = x_train[:, 1:]\n",
    "    x_test = x_test[:, 1:]\n",
    "\n",
    "    # sub-sample\n",
    "    if sub_sample:\n",
    "        y_train = y_train[::50]\n",
    "        x_train = x_train[::50]\n",
    "        train_ids = train_ids[::50]\n",
    "\n",
    "    return x_train, x_test, y_train, train_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ytrain done\n",
      "xtrain done\n",
      "xtest done\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_te, y_tr, tr_ids, te_ids = load_csv_data('dataset_to_release', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.50000000e+01 7.00000000e+00 7.16201500e+06 7.00000000e+00\n",
      " 1.60000000e+01 2.01500000e+03 1.10000000e+03 2.01500318e+09\n",
      " 2.01500318e+09 1.00000000e+00 1.00000000e+00            nan\n",
      " 1.00000000e+00 2.00000000e+00            nan 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan 3.00000000e+00 8.80000000e+01\n",
      " 8.80000000e+01            nan 1.00000000e+00 1.00000000e+00\n",
      " 2.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 2.00000000e+00\n",
      " 2.00000000e+00            nan 2.00000000e+00 1.00000000e+00\n",
      " 2.00000000e+00 1.00000000e+00 2.00000000e+00 2.00000000e+00\n",
      " 3.00000000e+00            nan 2.00000000e+00 2.00000000e+00\n",
      " 5.00000000e+00 1.00000000e+00 2.00000000e+00            nan\n",
      " 1.00000000e+00 2.00000000e+00 7.00000000e+00 8.80000000e+01\n",
      " 5.00000000e+00 1.00000000e+00 1.60000000e+02 5.06000000e+02\n",
      "            nan 2.00000000e+00 2.00000000e+00 2.00000000e+00\n",
      " 2.00000000e+00 2.00000000e+00 2.00000000e+00 2.00000000e+00\n",
      " 2.00000000e+00            nan            nan            nan\n",
      " 3.00000000e+00 8.88000000e+02            nan            nan\n",
      "            nan 1.01000000e+02 2.03000000e+02 5.55000000e+02\n",
      " 5.55000000e+02 2.03000000e+02 2.03000000e+02 2.00000000e+00\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan 8.88000000e+02 2.00000000e+00\n",
      " 2.00000000e+00 3.00000000e+00 4.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 7.77777000e+05 5.00000000e+00 2.00000000e+00\n",
      " 2.00000000e+00            nan            nan 2.00000000e+00\n",
      " 3.00000000e+00            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan 2.00000000e+00            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan 2.00000000e+00            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 2.00000000e+00            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan 1.00000000e+00 2.00000000e+00\n",
      " 2.00000000e+00 2.00000000e+00 7.00000000e+00            nan\n",
      "            nan 2.00000000e+00            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      " 1.00000000e+01 1.00000000e+00 1.00000000e+00 4.51071000e+05\n",
      " 9.74980452e+01 1.00000000e+00 9.74980452e+01 9.00000000e+00\n",
      "            nan            nan            nan 1.00000000e+00\n",
      " 6.26469876e-01 4.46957905e+02 1.00000000e+00 1.00000000e+00\n",
      " 2.00000000e+00 1.00000000e+00 2.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 3.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 2.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.00000000e+00 1.00000000e+00\n",
      " 6.20000000e+01 5.00000000e+00 6.60000000e+01 1.68000000e+00\n",
      " 7.25700000e+01 2.58200000e+01 3.00000000e+00 2.00000000e+00\n",
      " 1.00000000e+00 3.00000000e+00 3.00000000e+00 4.00000000e+00\n",
      " 1.00000000e+00 2.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 1.00000000e+00 4.30000000e-01\n",
      " 0.00000000e+00 0.00000000e+00 4.30000000e-01 4.30000000e-01\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.43000000e+00 8.60000000e-01 1.00000000e+00 2.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.00000000e+00            nan            nan 2.50600000e+01\n",
      " 4.30000000e+00            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan 0.00000000e+00 0.00000000e+00            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan 4.00000000e+00 2.00000000e+00 3.00000000e+00\n",
      " 3.00000000e+00 2.00000000e+00 2.00000000e+00 4.00000000e+00\n",
      " 2.00000000e+00 2.00000000e+00 2.00000000e+00 3.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00            nan            nan\n",
      " 2.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(x_tr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_type(data, dtype = 'numerical'):\n",
    "    float_columns = np.array([col_idx for col_idx, col in enumerate(data.T) if np.issubdtype(col.dtype, np.floating) and any((not np.isnan(x)) and (x % 1 != 0) for x in col)])\n",
    "    non_float_columns = np.setdiff1d(np.arange(data.shape[1]), float_columns)\n",
    "    if dtype == 'categorical':\n",
    "        return data[:, non_float_columns], non_float_columns\n",
    "    else:\n",
    "        return data[:, float_columns], float_columns\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical data is 297 features\n",
      "Numerical data is 24 features\n"
     ]
    }
   ],
   "source": [
    "categorical, cat_idx = data_type(x_tr, 'categorical')\n",
    "numerical, num_idx  = data_type(x_tr)\n",
    "print(f'Categorical data is {categorical.shape[1]} features')\n",
    "print(f'Numerical data is {numerical.shape[1]} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_columns(data,threshold):\n",
    "    #remove features with threshold for nan\n",
    "    nan_ratio = np.sum(np.isnan(data), axis = 0)/ data.shape[0]\n",
    "    columns_to_remove = np.where(nan_ratio > threshold)[0]\n",
    "    without_nan = np.delete(data, columns_to_remove, axis = 1)\n",
    "    return without_nan\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6563, 205)\n"
     ]
    }
   ],
   "source": [
    "ours_nonan = remove_nan_columns(x_tr, 0.8)\n",
    "print(ours_nonan.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_ratio = np.sum(np.isnan(ours_nonan), axis = 0)/ ours_nonan.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.43105287216212096\n",
      "0.43105287216212096\n",
      "0.43105287216212096\n",
      "0.43105287216212096\n",
      "0.4312052415054091\n",
      "0.43181471887856165\n",
      "0.43181471887856165\n",
      "0.568947127837879\n",
      "0.568947127837879\n",
      "0.568947127837879\n",
      "0.568947127837879\n",
      "0.568947127837879\n",
      "0.5695566052110316\n",
      "0.5832698461069633\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.4820966021636447\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.6047539235105897\n",
      "0.0\n",
      "0.14155111991467317\n",
      "0.14155111991467317\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.43105287216212096\n",
      "0.43105287216212096\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006856620447965869\n",
      "0.009142160597287825\n",
      "0.01097059271674539\n",
      "0.013103763522779217\n",
      "0.019960383970745087\n",
      "0.022703032149931433\n",
      "0.02468383361267713\n",
      "0.026512265732134693\n",
      "0.027274112448575347\n",
      "0.028035959165016\n",
      "0.02895017522474478\n",
      "0.030169129971049823\n",
      "0.5904312052415054\n",
      "0.7290873076337041\n",
      "0.030778607344202347\n",
      "0.03336888618010057\n",
      "0.5284168825232364\n",
      "0.5293310985829651\n",
      "0.5300929452994058\n",
      "0.05805271979277769\n",
      "0.059576413225659\n",
      "0.0626238000914216\n",
      "0.06369038549443852\n",
      "0.0661282949870486\n",
      "0.0685662044796587\n",
      "0.07405150083803139\n",
      "0.3193661435319214\n",
      "0.32226116105439584\n",
      "0.32302300777083653\n",
      "0.3239372238305653\n",
      "0.537406673777236\n",
      "0.5375590431205242\n",
      "0.08121285997257352\n",
      "0.6966326375133323\n",
      "0.6967850068566205\n",
      "0.6972421148864848\n",
      "0.7034892579612982\n",
      "0.0856315709279293\n",
      "0.08746000304738687\n",
      "0.5625476154197775\n",
      "0.5598049672405911\n",
      "0.0886789577936919\n",
      "0.09142160597287825\n",
      "0.7386865762608563\n",
      "0.7388389456041444\n",
      "0.7456955660521103\n",
      "0.7368581441413987\n",
      "0.6259332622276398\n",
      "0.6263903702575042\n",
      "0.0\n",
      "0.00015236934328813042\n",
      "0.43730001523693435\n",
      "0.0\n",
      "0.00015236934328813042\n",
      "0.0\n",
      "0.0\n",
      "0.26923662959012645\n",
      "0.0\n",
      "0.37040987353344507\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.14155111991467317\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006856620447965869\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.018436690537863783\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03641627304586317\n",
      "0.030321499314337957\n",
      "0.06551881761389608\n",
      "0.07587993295748895\n",
      "0.07587993295748895\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.08121285997257352\n",
      "0.07542282492762456\n",
      "0.0836507694651836\n",
      "0.07938442785311595\n",
      "0.08197470668901417\n",
      "0.08746000304738687\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.09081212859972573\n",
      "0.10894408045101325\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.3214993143379552\n",
      "0.33292701508456496\n",
      "0.0\n",
      "0.0\n",
      "0.32927015084564987\n",
      "0.34039311290568336\n",
      "0.33810757275636144\n",
      "0.5485296358372695\n",
      "0.3278988267560567\n",
      "0.5425872314490324\n",
      "0.34145969830870027\n",
      "0.3475544720402255\n",
      "0.09385951546548835\n",
      "0.0\n",
      "0.3486210574432424\n",
      "0.3545634618314795\n",
      "0.3346030778607344\n",
      "0.33810757275636144\n",
      "0.3472497333536492\n",
      "0.3314033216516837\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006856620447965869\n",
      "0.006856620447965869\n",
      "0.006856620447965869\n",
      "0.0\n",
      "0.0\n",
      "0.6501599878104526\n",
      "0.6501599878104526\n",
      "0.09142160597287825\n"
     ]
    }
   ],
   "source": [
    "for v in nan_ratio:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(array, categorical_indexes):\n",
    "    encoded_array = array.copy()\n",
    "\n",
    "    for index in categorical_indexes:\n",
    "        unique_values = set(row[index] for row in array)\n",
    "        for value in unique_values:\n",
    "            new_column = [1 if row[index] == value else 0 for row in array]\n",
    "            encoded_array = [row + [new_col] for row, new_col in zip(encoded_array, new_column)]\n",
    "\n",
    "    # Remove the original categorical columns\n",
    "    encoded_array = [row[:index] + row[index + 1:] for row in encoded_array for index in sorted(categorical_indexes, reverse=True)]\n",
    "\n",
    "    return encoded_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances = np.var(np.vstack([x_tr, x_te]), axis=0)\n",
    "\n",
    "# Step 2: Identify the indices of the top 10 features with the highest variance\n",
    "top_feature_indices = np.argsort(variances)[-10:]\n",
    "\n",
    "# Step 3: Extract the names of the top 10 features\n",
    "#top_feature_names = list(np.vstack([x_tr, x_te]).columns[top_feature_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 12,  11, 313, 314, 315,  10,   9, 318, 319, 320])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
