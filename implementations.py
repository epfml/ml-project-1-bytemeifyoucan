from helper import *

def mean_squared_error_gd(y, tx, initial w, max iters, gamma):

    loss = q
    w = 2
    return w, loss
    
    Note that all functions should return: (w, loss), which is 
    the last weight vector of the method, and the corresponding loss value 
    (cost function). Note that while in previous labs you might have kept track of all 
    encountered w for iterative methods, here we only want the last one. 
    
def mean_squared_error_sgd(y, tx, initial w, max iters, gamma):
    
def least_squares(y, tx):
    
def ridge_regression(y, tx, lambda ):
    #Moreover, 
    # the loss returned by the regularized methods (ridge regression and reg logistic regression) should not include the penalty term.
    
def logistic_regression(y, tx, initial w, max iters, gamma):
    
def reg_logistic_regression(y, tx, lambda , initial w, max iters, gamma)