{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *\n",
    "from processing import *\n",
    "from cleaning import *\n",
    "from definitions import ROOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(ROOT_DIR, 'dataset_to_release')\n",
    "x_tr, x_te, y_tr, tr_ids, te_ids = load_csv_data(dataset_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = False #if set to True will run PCA on continuous features and keep principal components until 99% of variance is explained\n",
    "cv = True #for the sake of time, if set to False will use premade list of best parameters already computed. Those same parameters can be found by keeping cv to True. \n",
    "split_ratio = 0.8 #80% of the dataset will be used to train the model, the rest will be used to evaluate performance\n",
    "nan_threshold = 0.8 #to filter our features with more nan than the threshold\n",
    "max_unique_values = 50 #when filtering out features w too many categories\n",
    "\n",
    "models = ['gradient descent', 'stochastic gradient descent', 'least squares', 'ridge regression',  'logistic regression', 'reg logistic regression']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing + cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "x_tr, x_te, y_tr, y_te = split_data(x_tr, y_tr, split_ratio)\n",
    "#clean both\n",
    "#run cv\n",
    "#train\n",
    "#evaluate perf\n",
    "clean_train = \n",
    "clean_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing\n",
    "\n",
    "#ad params for preprocessing like pca etc\n",
    "\n",
    "# for each model \n",
    "#find best parameters w cross validation it param set to true\n",
    "#hyperparam_tuning: True\n",
    "#if false use the ones we already found \n",
    "\n",
    "# for each model\n",
    "# find best hyperparam\n",
    "# run to get predictions\n",
    "# evaluate our predictions\n",
    "# make submission \n",
    "\n",
    "\n",
    "\n",
    "# we need to end up w/\n",
    "# - figures for cv for each param with other ones fixed\n",
    "# - best hyperparameter list if cv set to true \n",
    "# - figures for pca value decomposition evolution to show the optimal components\n",
    "# - plot of metrics for each model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
